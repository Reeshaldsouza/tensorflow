Develop a python program to build a TensorFlow model to predict y = 2x + 1 given a set of x values. Use a dataset of 10 points and plot the predicted vs actual results.



# Step 1: Import Required Libraries
# TensorFlow is an open-source framework for machine learning and deep learning.
# NumPy is a library for numerical computations in Python.
# Matplotlib is used for creating visualizations like graphs and plots.
import tensorflow as tf  # Import TensorFlow for building the neural network
import numpy as np  # Import NumPy for handling numerical data
import matplotlib.pyplot as plt  # Import Matplotlib for plotting graphs

# Step 2: Generate the Dataset
# We create a simple dataset where the relationship between x and y follows a linear equation: y = 2x + 1

x_train = np.array(range(10), dtype=np.float32)  # Generate x values from 0 to 9 as floating-point numbers
# Example: x_train = [0, 1, 2, 3, ..., 9]

y_train = 2 * x_train + 1  # Generate y values using the equation y = 2x + 1
# Example: If x = 0, y = 2(0) + 1 = 1; If x = 1, y = 2(1) + 1 = 3; and so on.

# Step 3: Build a Simple Linear Model
# We define a neural network model with one layer and one neuron.
# Since we are solving a simple linear regression problem, we need only 1 neuron.

model = tf.keras.Sequential([  # Create a sequential model (layers are stacked in sequence)
    tf.keras.layers.Dense(units=1, input_shape=[1])  # A dense (fully connected) layer with 1 neuron
    # The input_shape=[1] means that the model expects a single input feature (x values).
    # The layer learns the parameters (weight and bias) to approximate the equation y = mx + c.
])

# Step 4: Compile the Model
# Before training, we need to specify how the model should learn.
# - Optimizer: Stochastic Gradient Descent (SGD) adjusts the weights to minimize errors.
# - Loss function: Mean Squared Error (MSE) measures how far predictions are from actual values.

model.compile(optimizer='sgd', loss='mse')  # Compile the model with SGD optimizer and MSE loss function

# Step 5: Train the Model
# - The model learns from the dataset by adjusting its parameters (weight and bias) over multiple epochs.
# - Epochs: The number of times the model goes through the entire dataset.
# - verbose=0 means training progress will not be displayed (to keep the output clean).

model.fit(x_train, y_train, epochs=100, verbose=0)  # Train the model for 100 epochs

# Step 6: Predict Values Using the Trained Model
# Now that the model is trained, we use it to predict y values for the given x values.

y_pred = model.predict(x_train)  # Use the trained model to make predictions on x_train

# Step 7: Plot Actual vs Predicted Values
# We will visualize how well the model has learned by plotting actual vs predicted values.

plt.scatter(x_train, y_train, label="Actual", color="blue")  # Plot actual data points as a scatter plot (blue dots)
plt.plot(x_train, y_pred, label="Predicted", color="red", linewidth=2)  # Plot predicted values as a red line

# Add labels and title for better understanding
plt.xlabel("x values")  # Label for x-axis
plt.ylabel("y values")  # Label for y-axis
plt.title("Actual vs Predicted")  # Title of the plot
plt.legend()  # Display the legend to differentiate between actual and predicted values
plt.show()  # Show the final plot
