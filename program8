Develop a ANN using TensorFlow to classify email as spam or not using available dataset. Evaluate the model performance using metrics such as accuracy, precision, and recall on a test dataset.

# Import necessary libraries
# - numpy: For numerical operations
# - pandas: For data loading and manipulation
# - tensorflow: For building and training neural networks
# - sklearn: For data splitting, preprocessing, and evaluation metrics
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score

# --------------------------------------------------------------------------
# STEP 1: LOAD AND PREPARE THE DATA
# --------------------------------------------------------------------------

# Load the Spambase dataset from UCI Machine Learning Repository
# - This dataset contains 57 features extracted from emails
# - Last column is the label (1 = spam, 0 = not spam)
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data"
data = pd.read_csv(url, header=None)  # No header in the original file

# Split data into features (X) and labels (y)
# - X: All columns except the last one (features)
# - y: Last column (labels)
X = data.iloc[:, :-1].values  # .values converts to NumPy array
y = data.iloc[:, -1].values

# Split into training (80%) and testing (20%) sets
# - random_state=42 ensures reproducible results
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Standardize the features (mean=0, std=1)
# - Critical for neural network performance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # Fit to training data
X_test = scaler.transform(X_test)  # Apply same transformation to test data

# --------------------------------------------------------------------------
# STEP 2: BUILD THE NEURAL NETWORK MODEL
# --------------------------------------------------------------------------

# Create a Sequential model (linear stack of layers)
model = tf.keras.Sequential([
    # First hidden layer:
    # - 32 neurons (units)
    # - ReLU activation function (returns max(0, x))
    # - input_shape: Must specify input size for first layer (57 features)
    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),

    # Output layer:
    # - 1 neuron (binary classification)
    # - Sigmoid activation (outputs probability between 0 and 1)
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model (configure learning process)
# - optimizer='adam': Adaptive learning rate algorithm
# - loss='binary_crossentropy': Loss function for binary classification
# - metrics=['accuracy']: Track accuracy during training
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# --------------------------------------------------------------------------
# STEP 3: TRAIN THE MODEL
# --------------------------------------------------------------------------

print("\nTraining the model...")
# Fit the model to the training data:
# - epochs=10: Number of passes through entire dataset
# - batch_size=32: Number of samples per gradient update
# - verbose=1: Show progress bar
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    verbose=1
)

# --------------------------------------------------------------------------
# STEP 4: EVALUATE THE MODEL
# --------------------------------------------------------------------------

print("\nEvaluating on test set...")
# Evaluate model on test data:
# - Returns loss value and metrics (accuracy)
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

# Make predictions (output is probability between 0-1)
# Convert probabilities to binary predictions (0 or 1) using 0.5 threshold
y_pred = (model.predict(X_test) > 0.5).astype(int)

# Calculate evaluation metrics:
# - Accuracy: Overall correctness
# - Precision: % of predicted spam that was actually spam
# - Recall: % of actual spam correctly identified
print("\nModel Performance Metrics:")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision: {precision_score(y_test, y_pred):.4f}")
print(f"Recall: {recall_score(y_test, y_pred):.4f}")

# --------------------------------------------------------------------------
# OPTIONAL: VISUALIZATION
# --------------------------------------------------------------------------

# Uncomment to plot training history
"""
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.title('Training Accuracy')
plt.xlabel('Epoch'); plt.ylabel('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.title('Training Loss')
plt.xlabel('Epoch'); plt.ylabel('Loss')
plt.show()
"""
